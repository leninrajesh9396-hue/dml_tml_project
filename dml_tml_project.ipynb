{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVVTK401GmhSmIfItmH5Rb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNNX4e6gsZ1k","executionInfo":{"status":"ok","timestamp":1763364716562,"user_tz":-330,"elapsed":62,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"90491587-be61-450a-889a-e2c92dcaacbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ready. If you need to install, uncomment the pip line above.\n"]}],"source":["# Run this first in Colab if packages missing.\n","# (Uncomment the pip line if running in a clean environment)\n","# !pip install -q statsmodels scikit-learn matplotlib seaborn\n","\n","import os\n","print(\"Ready. If you need to install, uncomment the pip line above.\")\n"]},{"cell_type":"code","source":["import os, json, math\n","import numpy as np, pandas as pd\n","import matplotlib.pyplot as plt, seaborn as sns\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import roc_auc_score\n","import statsmodels.api as sm\n","from scipy.special import expit, logit\n","\n","PROJECT = \"/content/dml_tml_project\"\n","PLOTS = os.path.join(PROJECT, \"plots\")\n","os.makedirs(PLOTS, exist_ok=True)\n","print(\"Project folder:\", PROJECT)\n","print(\"Plots folder:\", PLOTS)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJA--XNruiEg","executionInfo":{"status":"ok","timestamp":1763364727303,"user_tz":-330,"elapsed":8813,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"c634cf4b-b760-4a61-f146-3b3ca4ccde8d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Project folder: /content/dml_tml_project\n","Plots folder: /content/dml_tml_project/plots\n"]}]},{"cell_type":"code","source":["np.random.seed(42)\n","n = 12000  # moderate size under 5MB CSV\n","# covariates\n","W = pd.DataFrame({\n","    \"x1\": np.random.normal(0,1,n),\n","    \"x2\": np.random.normal(0,1,n),\n","    \"x3\": np.random.randint(0,4,n).astype(float),\n","    \"x4\": np.random.choice([0,1], size=n, p=[0.6,0.4]),   # binary cov\n","})\n","# true propensity (depends on W)\n","logit_g = -0.2 + 0.6*W[\"x1\"] - 0.3*W[\"x3\"] + 0.4*W[\"x4\"]\n","prob_t = 1/(1+np.exp(-logit_g))\n","T = np.random.binomial(1, prob_t, size=n)\n","\n","# true treatment effect heterogeneous: depends on x1 & x4\n","true_tau = 0.8*(W[\"x1\"]>0).astype(float) + 0.5*W[\"x4\"]\n","\n","# baseline outcome\n","mu0 = 0.5*W[\"x1\"] - 0.3*W[\"x2\"] + 0.1*W[\"x3\"] - 0.4*W[\"x4\"] + np.random.normal(0,0.6,n)\n","# potential outcomes\n","Y0 = (logit(mu0) if False else mu0)  # keep continuous latent; we'll make binary outcome\n","Y1_cont = mu0 + true_tau\n","# convert to probability via logistic and draw binary outcome\n","p0 = expit(Y0)\n","p1 = expit(Y1_cont)\n","Y = np.array([np.random.binomial(1, p1[i]) if T[i]==1 else np.random.binomial(1, p0[i]) for i in range(n)])\n","\n","df = pd.concat([W, pd.Series(T, name=\"treatment\"), pd.Series(Y, name=\"outcome\")], axis=1)\n","csv_path = os.path.join(PROJECT, \"synthetic_causal_dataset.csv\")\n","df.to_csv(csv_path, index=False)\n","print(\"Saved synthetic dataset:\", csv_path)\n","print(\"Default sizes: n =\", len(df), \"treatment rate:\", df['treatment'].mean())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IYGJReWuiM8","executionInfo":{"status":"ok","timestamp":1763364730884,"user_tz":-330,"elapsed":107,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"deaa0c8a-1c30-4dcb-a0f5-5b60da5ee846"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved synthetic dataset: /content/dml_tml_project/synthetic_causal_dataset.csv\n","Default sizes: n = 12000 treatment rate: 0.39166666666666666\n"]}]},{"cell_type":"code","source":["# Basic EDA: covariate means by treatment\n","summary = df.groupby(\"treatment\")[[\"x1\",\"x2\",\"x3\",\"x4\"]].mean().T\n","print(\"Mean covariates by treatment:\\n\", summary)\n","\n","# Standardized mean differences (SMD)\n","def smd(df, col, treat_col=\"treatment\"):\n","    m1 = df.loc[df[treat_col]==1, col].mean()\n","    m0 = df.loc[df[treat_col]==0, col].mean()\n","    s = np.sqrt((df[col].var()))\n","    return (m1 - m0)/s\n","\n","smds = {c: smd(df, c) for c in [\"x1\",\"x2\",\"x3\",\"x4\"]}\n","print(\"SMDs (pre-adjustment):\", smds)\n","\n","# Plot distributions for x1,x2 by treatment\n","for col in [\"x1\",\"x2\"]:\n","    plt.figure(figsize=(6,3))\n","    sns.kdeplot(df.loc[df.treatment==0, col], label=\"control\", bw_adjust=1.2)\n","    sns.kdeplot(df.loc[df.treatment==1, col], label=\"treated\", bw_adjust=1.2)\n","    plt.title(f\"Distribution of {col} by treatment\")\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(PLOTS, f\"dist_{col}_by_treatment.png\"))\n","    plt.close()\n","print(\"Saved EDA plots to\", PLOTS)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_7BsftLuiRH","executionInfo":{"status":"ok","timestamp":1763364740507,"user_tz":-330,"elapsed":980,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"26443067-1318-44c8-b45a-aec61802af11"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean covariates by treatment:\n"," treatment         0         1\n","x1        -0.215736  0.319662\n","x2         0.001832  0.022126\n","x3         1.644384  1.300638\n","x4         0.360685  0.455106\n","SMDs (pre-adjustment): {'x1': np.float64(0.5345057055574404), 'x2': np.float64(0.020303977031750072), 'x3': np.float64(-0.3091487783199045), 'x4': np.float64(0.1929187913997293)}\n","Saved EDA plots to /content/dml_tml_project/plots\n"]}]},{"cell_type":"code","source":["X = df[[\"x1\",\"x2\",\"x3\",\"x4\"]]\n","y_t = df[\"treatment\"]\n","ps_model = LogisticRegression(max_iter=2000)\n","ps_model.fit(X, y_t)\n","propensity = ps_model.predict_proba(X)[:,1]\n","df[\"propensity\"] = propensity\n","\n","plt.figure(figsize=(6,4))\n","sns.histplot(df[df.treatment==1]['propensity'], label=\"treated\", kde=True, stat=\"density\", color=\"C1\")\n","sns.histplot(df[df.treatment==0]['propensity'], label=\"control\", kde=True, stat=\"density\", color=\"C0\")\n","plt.legend(); plt.title(\"Propensity score distribution\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(PLOTS,\"propensity_distribution.png\")); plt.close()\n","print(\"Saved propensity distribution.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CL9P1vcfuiYC","executionInfo":{"status":"ok","timestamp":1763364752348,"user_tz":-330,"elapsed":669,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"5c2ede82-22f7-4002-85c5-2d07cac1a714"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved propensity distribution.\n"]}]},{"cell_type":"code","source":["# stabilized weights\n","p = df[\"propensity\"].values\n","t = df[\"treatment\"].values\n","# stabilized numerator: marginal probability of treatment\n","p_t = t.mean()\n","p_c = 1 - p_t\n","stabilized_w = np.where(t==1, p_t / p, p_c / (1-p))\n","df[\"ipw_stabilized\"] = stabilized_w\n","\n","# SMD after weighting (weighted means)\n","def weighted_mean(df, col, weight_col, group_val):\n","    w = df.loc[df.treatment==group_val, weight_col]\n","    x = df.loc[df.treatment==group_val, col]\n","    return (w * x).sum() / w.sum()\n","\n","smd_post = {}\n","for c in [\"x1\",\"x2\",\"x3\",\"x4\"]:\n","    m1 = weighted_mean(df, c, \"ipw_stabilized\", 1)\n","    m0 = weighted_mean(df, c, \"ipw_stabilized\", 0)\n","    pooled_sd = np.sqrt(((df[c].var())))\n","    smd_post[c] = (m1 - m0)/pooled_sd\n","print(\"SMD post-weighting:\", smd_post)\n","\n","# plot SMD before/after\n","cols = [\"x1\",\"x2\",\"x3\",\"x4\"]\n","before = [smds[c] for c in cols]\n","after = [smd_post[c] for c in cols]\n","xpos = np.arange(len(cols))\n","plt.figure(figsize=(6,3))\n","plt.bar(xpos-0.15, before, width=0.3, label=\"before\")\n","plt.bar(xpos+0.15, after, width=0.3, label=\"after\")\n","plt.axhline(0.1, color='red', linestyle='--', linewidth=0.7)\n","plt.xticks(xpos, cols)\n","plt.ylabel(\"Standardized mean diff\")\n","plt.legend()\n","plt.title(\"Covariate balance before/after IPW\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(PLOTS,\"smd_before_after.png\"))\n","plt.close()\n","print(\"Saved covariate balance plot.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EP_hunfBuifH","executionInfo":{"status":"ok","timestamp":1763364759390,"user_tz":-330,"elapsed":332,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"223a81d2-dda2-4b7f-a323-4ba72653dd45"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["SMD post-weighting: {'x1': np.float64(0.006101721855257966), 'x2': np.float64(0.0056609049736738165), 'x3': np.float64(-0.00557020019440208), 'x4': np.float64(0.005810109628728016)}\n","Saved covariate balance plot.\n"]}]},{"cell_type":"code","source":["from sklearn.base import clone\n","K = 5\n","kf = KFold(n_splits=K, shuffle=True, random_state=42)\n","\n","# learners\n","m_model = GradientBoostingRegressor(n_estimators=200, max_depth=3, random_state=1)  # outcome model\n","g_model = GradientBoostingClassifier(n_estimators=200, max_depth=3, random_state=2)  # propensity\n","\n","n = len(df)\n","theta_vals = []\n","psi_list = []\n","\n","# arrays to store predictions\n","m_hat = np.zeros(n)\n","g_hat = np.zeros(n)\n","\n","X_vals = df[[\"x1\",\"x2\",\"x3\",\"x4\"]].values\n","Y_vals = df[\"outcome\"].values\n","T_vals = df[\"treatment\"].values\n","\n","for train_idx, test_idx in kf.split(X_vals):\n","    # fit nuisance models on train\n","    m = clone(m_model)\n","    g = clone(g_model)\n","    m.fit(X_vals[train_idx], Y_vals[train_idx])\n","    g.fit(X_vals[train_idx], T_vals[train_idx])\n","    # predict on test\n","    m_hat[test_idx] = m.predict(X_vals[test_idx])\n","    g_hat[test_idx] = g.predict_proba(X_vals[test_idx])[:,1]\n","\n","# residuals\n","res_y = Y_vals - m_hat\n","res_t = T_vals - g_hat\n","\n","# final theta via linear regression of res_y on res_t (simple OLS)\n","theta = np.sum(res_t * res_y) / np.sum(res_t * res_t)\n","# compute std err (influence function)\n","psi = res_t * (res_y - theta * res_t)\n","se = np.std(psi) / np.sqrt(n)\n","ci_low = theta - 1.96*se\n","ci_high = theta + 1.96*se\n","\n","print(\"DML ATE estimate:\", theta, \"SE:\", se, \"95% CI:\", (ci_low,ci_high))\n","df_results = {\"dml_ate\": float(theta), \"dml_se\": float(se), \"dml_ci\": [float(ci_low), float(ci_high)]}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mk0GB8eDuijo","executionInfo":{"status":"ok","timestamp":1763364798608,"user_tz":-330,"elapsed":31081,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"26810131-d299-4fd0-a706-84bb58ebe984"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["DML ATE estimate: 0.11833601067442741 SE: 0.0020232097132245274 95% CI: (np.float64(0.11437051963650734), np.float64(0.12230150171234748))\n"]}]},{"cell_type":"code","source":["# We'll implement TMLE for ATE (binary outcome) using logistic fluctuation\n","\n","# 1) fit initial outcome regression Q(A,W) predicting E[Y|A,W]\n","X_aw = np.hstack([X_vals, T_vals.reshape(-1,1)])  # features + treatment\n","Q_model = GradientBoostingRegressor(n_estimators=200, max_depth=3, random_state=3)\n","Q_model.fit(X_aw, Y_vals)  # fits for outcome on A and W\n","\n","# predict Q0 and Q1 (for all obs)\n","X0 = np.hstack([X_vals, np.zeros((n,1))])\n","X1 = np.hstack([X_vals, np.ones((n,1))])\n","Q0 = Q_model.predict(X0)\n","Q1 = Q_model.predict(X1)\n","# truncate to (eps,1-eps) after passing through logit if necessary; we'll use expit(logit) later\n","# estimate initial ATE (plug-in)\n","psi_initial = (Q1 - Q0).mean()\n","\n","# 2) fit propensity g (already have g_hat from DML - but re-use full-sample fit)\n","g_full = clone(g_model)\n","g_full.fit(X_vals, T_vals)\n","g_full_p = g_full.predict_proba(X_vals)[:,1]\n","\n","# 3) clever covariate H = A/g + (1-A)/ (1-g) ?? For ATE use H = A/g - (1-A)/(1-g)\n","H = (T_vals / g_full_p) - ((1-T_vals) / (1 - g_full_p))\n","\n","# 4) logistic fluctuation: transform Q (continuous predictions) to logit-scale probabilities\n","# ensure values in (eps,1-eps)\n","eps = 1e-6\n","q0_p = np.clip(Q_model.predict(X_aw) , 1e-3, 1-1e-3)  # but Q_model returns continuous; instead use expit(Q)\n","# better: treat Q0/Q1 as logits? We'll map predicted continuous to probability via expit\n","Q0_p = np.clip(expit(Q0), 1e-6, 1-1e-6)\n","Q1_p = np.clip(expit(Q1), 1e-6, 1-1e-6)\n","Q_p = np.clip(expit(Q_model.predict(X_aw)), 1e-6, 1-1e-6)\n","\n","# Fit epsilon via weighted logistic regression with offset = logit(Q_p) and covariate H\n","# Using statsmodels: endog = Y, exog = H (constant included), offset = logit(Q_p)\n","logit_Q = np.log(Q_p/(1-Q_p))\n","# add small constant to offset to avoid inf\n","exog = sm.add_constant(H)  # include intercept and H\n","glm_binom = sm.GLM(Y_vals, exog, family=sm.families.Binomial(), offset=logit_Q)\n","res_glm = glm_binom.fit()\n","# epsilon = coefficient on H (exog column 1)\n","eps_hat = res_glm.params[1]\n","print(\"Estimated fluctuation epsilon:\", eps_hat)\n","\n","# update Q* = expit(logit(Q_p) + epsilon * H)\n","Q_star = expit(logit_Q + eps_hat * H)\n","\n","# Now compute targeted estimates of Q1* and Q0* by adjusting individual-level predictions:\n","# For each observation, compute updated Q1_star_i and Q0_star_i as:\n","# Q1_star_i = expit( logit(Q1_p_i) + eps_hat * (1/g_i) )\n","# Q0_star_i = expit( logit(Q0_p_i) + eps_hat * (-1/(1-g_i)) )\n","Q1_star = expit(np.log(Q1_p/(1-Q1_p)) + eps_hat * (1.0 / g_full_p))\n","Q0_star = expit(np.log(Q0_p/(1-Q0_p)) + eps_hat * (-1.0 / (1 - g_full_p)))\n","\n","tmle_psi = np.mean(Q1_star - Q0_star)\n","# approximate std error using influence function\n","IF = ((T_vals / g_full_p) * (Y_vals - Q_p)) + (Q1_star - Q0_star - tmle_psi)\n","tmle_se = np.std(IF) / np.sqrt(n)\n","tmle_ci = (tmle_psi - 1.96*tmle_se, tmle_psi + 1.96*tmle_se)\n","\n","print(\"TMLE ATE:\", tmle_psi, \"SE:\", tmle_se, \"95% CI:\", tmle_ci)\n","df_results.update({\"tmle_ate\": float(tmle_psi), \"tmle_se\": float(tmle_se), \"tmle_ci\": [float(tmle_ci[0]), float(tmle_ci[1])]})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFCj2HuXuiop","executionInfo":{"status":"ok","timestamp":1763364804337,"user_tz":-330,"elapsed":5706,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"f272a9c4-7b46-4bb0-8efa-a0bda57f7a7e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Estimated fluctuation epsilon: 0.08131834331419424\n","TMLE ATE: 0.11559623240567293 SE: 0.007277577888057607 95% CI: (np.float64(0.10133217974508002), np.float64(0.12986028506626585))\n"]}]},{"cell_type":"code","source":["sub_mask = df[\"x1\"] > 0\n","print(\"Subgroup size:\", sub_mask.sum(), \"total:\", len(df))\n","# DML on subgroup (simple: re-run DML steps restricted to subgroup)\n","X_sub = df.loc[sub_mask, [\"x1\",\"x2\",\"x3\",\"x4\"]].values\n","Y_sub = df.loc[sub_mask, \"outcome\"].values\n","T_sub = df.loc[sub_mask, \"treatment\"].values\n","# fit nuisance on subgroup full-sample (no cross-fitting here for speed) -- acceptable for report but note in writeup\n","m = GradientBoostingRegressor(n_estimators=200, max_depth=3)\n","g = GradientBoostingClassifier(n_estimators=200, max_depth=3)\n","m.fit(np.hstack([X_sub, T_sub.reshape(-1,1)]), Y_sub)  # outcome on A,W\n","g.fit(X_sub, T_sub)\n","m_hat_sub = m.predict(np.hstack([X_sub, T_sub.reshape(-1,1)]))\n","g_hat_sub = g.predict_proba(X_sub)[:,1]\n","res_y_sub = Y_sub - m_hat_sub\n","res_t_sub = T_sub - g_hat_sub\n","theta_sub = np.sum(res_t_sub * res_y_sub)/np.sum(res_t_sub * res_t_sub)\n","se_sub = np.std(res_t_sub * (res_y_sub - theta_sub*res_t_sub)) / np.sqrt(sub_mask.sum())\n","ci_sub = (theta_sub - 1.96*se_sub, theta_sub + 1.96*se_sub)\n","\n","# TMLE on subgroup (similar to above but restricted)\n","g_sub = g\n","g_sub_p = g_sub.predict_proba(X_sub)[:,1]\n","# initial Q on subgroup\n","Qm = GradientBoostingRegressor(n_estimators=200, max_depth=3)\n","Qm.fit(np.hstack([X_sub, T_sub.reshape(-1,1)]), Y_sub)\n","Q0_sub = expit(Qm.predict(np.hstack([X_sub, np.zeros((len(X_sub),1))])))\n","Q1_sub = expit(Qm.predict(np.hstack([X_sub, np.ones((len(X_sub),1))])))\n","# estimate eps via glm\n","H_sub = (T_sub / g_sub_p) - ((1-T_sub) / (1 - g_sub_p))\n","Qp_sub = np.clip(expit(Qm.predict(np.hstack([X_sub, T_sub.reshape(-1,1)]))),1e-6,1-1e-6)\n","logit_Qp_sub = np.log(Qp_sub/(1-Qp_sub))\n","exog_sub = sm.add_constant(H_sub)\n","glm_binom_sub = sm.GLM(Y_sub, exog_sub, family=sm.families.Binomial(), offset=logit_Qp_sub)\n","res_glm_sub = glm_binom_sub.fit()\n","eps_sub = res_glm_sub.params[1]\n","Q1_star_sub = expit(np.log(Q1_sub/(1-Q1_sub)) + eps_sub * (1.0 / g_sub_p))\n","Q0_star_sub = expit(np.log(Q0_sub/(1-Q0_sub)) + eps_sub * (-1.0 / (1 - g_sub_p)))\n","tmle_sub = np.mean(Q1_star_sub - Q0_star_sub)\n","IF_sub = ((T_sub / g_sub_p) * (Y_sub - Qp_sub)) + (Q1_star_sub - Q0_star_sub - tmle_sub)\n","tmle_sub_se = np.std(IF_sub)/np.sqrt(len(X_sub))\n","tmle_sub_ci = (tmle_sub - 1.96*tmle_sub_se, tmle_sub + 1.96*tmle_sub_se)\n","\n","print(\"Subgroup DML ATE:\", theta_sub, \"SE:\", se_sub, \"CI:\", ci_sub)\n","print(\"Subgroup TMLE ATE:\", tmle_sub, \"SE:\", tmle_sub_se, \"CI:\", tmle_sub_ci)\n","\n","df_results.update({\n","    \"sub_dml_ate\": float(theta_sub), \"sub_dml_se\": float(se_sub), \"sub_dml_ci\": [float(ci_sub[0]), float(ci_sub[1])],\n","    \"sub_tmle_ate\": float(tmle_sub), \"sub_tmle_se\": float(tmle_sub_se), \"sub_tmle_ci\": [float(tmle_sub_ci[0]), float(tmle_sub_ci[1])]\n","})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaheXARwuit4","executionInfo":{"status":"ok","timestamp":1763364811486,"user_tz":-330,"elapsed":7061,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"c85bdaf1-7bb4-48a8-ac25-260883b6f05d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Subgroup size: 5964 total: 12000\n","Subgroup DML ATE: 0.00887137989735717 SE: 0.0025210283511936334 CI: (np.float64(0.003930164329017648), np.float64(0.013812595465696692))\n","Subgroup TMLE ATE: 0.21055520200649794 SE: 0.007615623961895639 CI: (np.float64(0.1956285790411825), np.float64(0.22548182497181338))\n"]}]},{"cell_type":"code","source":["# Save results JSON\n","results_path = os.path.join(PROJECT, \"results_summary.json\")\n","with open(results_path, \"w\") as f:\n","    json.dump(df_results, f, indent=2)\n","print(\"Saved results to\", results_path)\n","\n","# Example plot: compare ATE estimates bar\n","plt.figure(figsize=(6,3))\n","methods = [\"DML\",\"TMLE\",\"Sub-DML\",\"Sub-TMLE\"]\n","vals = [df_results[\"dml_ate\"], df_results[\"tmle_ate\"], df_results[\"sub_dml_ate\"], df_results[\"sub_tmle_ate\"]]\n","errs = [df_results[\"dml_se\"]*1.96, df_results[\"tmle_se\"]*1.96, df_results[\"sub_dml_se\"]*1.96, df_results[\"sub_tmle_se\"]*1.96]\n","plt.bar(methods, vals, yerr=errs, capsize=6)\n","plt.ylabel(\"ATE estimate\")\n","plt.title(\"ATE estimates (95% CI)\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(PLOTS,\"ate_comparison.png\"))\n","plt.close()\n","print(\"Saved ATE comparison plot to\", PLOTS)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjYWoO6Vuiyc","executionInfo":{"status":"ok","timestamp":1763364811685,"user_tz":-330,"elapsed":185,"user":{"displayName":"Saravanan R","userId":"10246586932056038083"}},"outputId":"68768b6f-e1b5-4c24-ebfe-58f3e72ac700"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved results to /content/dml_tml_project/results_summary.json\n","Saved ATE comparison plot to /content/dml_tml_project/plots\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jBpXp_mPui3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BzK8fqgPui8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NiQsSlQZujCY"},"execution_count":null,"outputs":[]}]}